nohup: ignoring input
using train split as val split
GPU available: True, used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/data_loading.py:133: UserWarning: The dataloader, test_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 12 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  f"The dataloader, {name}, does not have many workers which may be a bottleneck."
Testing: 0it [00:00, ?it/s]Traceback (most recent call last):
  File "save_panoptic_features.py", line 46, in <module>
    main()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/click/core.py", line 829, in __call__
    return self.main(*args, **kwargs)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/click/core.py", line 782, in main
    rv = self.invoke(ctx)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/click/core.py", line 1066, in invoke
    return ctx.invoke(self.callback, **ctx.params)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/click/core.py", line 610, in invoke
    return callback(*args, **kwargs)
  File "save_panoptic_features.py", line 43, in main
    trainer.test(model,data.train_dataloader())
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 911, in test
    return self._call_and_handle_interrupt(self._test_impl, model, dataloaders, ckpt_path, verbose, datamodule)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 685, in _call_and_handle_interrupt
    return trainer_fn(*args, **kwargs)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 954, in _test_impl
    results = self._run(model, ckpt_path=self.tested_ckpt_path)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1199, in _run
    self._dispatch()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1275, in _dispatch
    self.training_type_plugin.start_evaluating(self)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 206, in start_evaluating
    self._results = trainer.run_stage()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1286, in run_stage
    return self._run_evaluate()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/trainer/trainer.py", line 1334, in _run_evaluate
    eval_loop_results = self._evaluation_loop.run()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py", line 110, in advance
    dl_outputs = self.epoch_loop.run(dataloader, dataloader_idx, dl_max_batches, self.num_dataloaders)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/loops/base.py", line 145, in run
    self.advance(*args, **kwargs)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 122, in advance
    output = self._evaluation_step(batch, batch_idx, dataloader_idx)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/loops/epoch/evaluation_epoch_loop.py", line 213, in _evaluation_step
    output = self.trainer.accelerator.test_step(step_kwargs)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/accelerators/accelerator.py", line 244, in test_step
    return self.training_type_plugin.test_step(*step_kwargs.values())
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py", line 222, in test_step
    return self.model.test_step(*args, **kwargs)
  File "/workspace/code/contrastive_association/cont_assoc/models/panoptic_models.py", line 59, in test_step
    sem_logits, pred_offsets, pt_ins_feat, raw_features = self(x)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/code/contrastive_association/cont_assoc/models/panoptic_models.py", line 53, in forward
    predicted_offsets, pt_ins_feat = self.instance_head(instance_feat, x)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/workspace/code/contrastive_association/cont_assoc/models/panoptic_models.py", line 188, in forward
    out = out.dense()
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/spconv/__init__.py", line 101, in dense
    output_shape)
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/spconv/__init__.py", line 44, in scatter_nd
    ret = torch.zeros(*shape, dtype=updates.dtype, device=updates.device)
RuntimeError: CUDA out of memory. Tried to allocate 1.32 GiB (GPU 0; 23.65 GiB total capacity; 817.45 MiB already allocated; 160.25 MiB free; 1000.00 MiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
Exception ignored in: <function tqdm.__del__ at 0x7f8b55131a70>
Traceback (most recent call last):
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/tqdm/std.py", line 1087, in __del__
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/tqdm/std.py", line 1294, in close
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/tqdm/std.py", line 1472, in display
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/tqdm/std.py", line 1090, in __repr__
  File "/opt/conda/envs/ca/lib/python3.7/site-packages/tqdm/std.py", line 1434, in format_dict
TypeError: cannot unpack non-iterable NoneType object
